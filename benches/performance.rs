use message_io::network::{self, Transport};

use criterion::{criterion_group, criterion_main, Criterion, BenchmarkId, Throughput};

use std::time::{Duration};
use std::thread::{self};
use std::sync::{
    Arc,
    atomic::{AtomicBool, Ordering},
};

lazy_static::lazy_static! {
    pub static ref SMALL_TIMEOUT: Duration = Duration::from_millis(100);
}

// Common error messages
pub const TIMEOUT_MSG_EXPECTED_ERR: &'static str = "Timeout, but a message was expected.";

fn latency_by(c: &mut Criterion, transport: Transport) {
    let msg = format!("latency by {}", transport);
    c.bench_function(&msg, |b| {
        let (controller, mut processor) = network::split();
        processor.run(|_| ()); // We need the processor running to process the connection

        let receiver_addr = controller.listen(transport, "127.0.0.1:0").unwrap().1;
        let receiver = controller.connect(transport, receiver_addr).unwrap().0;

        std::thread::sleep(std::time::Duration::from_millis(100)); // Connection processed
        processor.handler().finalize();
        processor.wait(); // Wait the thread to be totally stopped before counting time

        b.iter(|| {
            controller.send(receiver, &[0xFF]);
            processor.receive(Some(*SMALL_TIMEOUT), |_| ()); // It is ok, no cached event here.
        });
    });
}

fn throughput_by(c: &mut Criterion, transport: Transport) {
    let sizes = [1, 2, 4, 8, 16, 32, 64, 128]
        .iter()
        .map(|i| i * 1024)
        .filter(|&size| size < transport.max_message_size());

    for block_size in sizes {
        let mut group = c.benchmark_group(format!("throughput by {}", transport));
        group.throughput(Throughput::Bytes(block_size as u64));
        group.bench_with_input(BenchmarkId::from_parameter(block_size), &block_size, |b, &size| {
            let (controller, mut processor) = network::split();
            processor.run(|_| ());

            let receiver_addr = controller.listen(transport, "127.0.0.1:0").unwrap().1;
            let receiver = controller.connect(transport, receiver_addr).unwrap().0;

            std::thread::sleep(std::time::Duration::from_millis(100)); // Connection processed
            processor.handler().finalize();
            processor.wait();

            let thread_running = Arc::new(AtomicBool::new(true));
            let running = thread_running.clone();
            let (tx, rx) = std::sync::mpsc::channel();
            let handle = thread::Builder::new()
                .name("test-server".into())
                .spawn(move || {
                    let message = (0..size).map(|_| 0xFF).collect::<Vec<u8>>();
                    tx.send(()).unwrap(); // receiving thread ready
                    while running.load(Ordering::Relaxed) {
                        controller.send(receiver, &message);
                    }
                })
                .unwrap();

            rx.recv().unwrap();

            b.iter(move || {
                // FIX_IT!
                // There is two ways to receive an event: NetworkProcessor::run()
                // and NetworkProcessor::receive().
                // The first one can no mix it with criterion.
                // The second one hangs because receive, after receives the first event,
                // it will try to cache any other events generated by the same PollEvent.
                // Since the sender do not stop sends, the internal socket is wake up by the poll
                // to read "infinite" data. 1 PollEvent => inf. NetEvent::Message.
                processor.receive(Some(*SMALL_TIMEOUT), move |_| ());
            });

            thread_running.store(false, Ordering::Relaxed);
            handle.join().unwrap();
        });
    }
}

fn latency(c: &mut Criterion) {
    #[cfg(feature = "udp")]
    latency_by(c, Transport::Udp);
    #[cfg(feature = "tcp")]
    latency_by(c, Transport::Tcp);
    #[cfg(feature = "tcp")]
    latency_by(c, Transport::FramedTcp);
    #[cfg(feature = "websocket")]
    latency_by(c, Transport::Ws);
}

#[allow(dead_code)] //TODO: remove when the throughput test works fine
fn throughput(c: &mut Criterion) {
    #[cfg(feature = "udp")]
    throughput_by(c, Transport::Udp);
    // TODO: Fix this test: How to read inside of criterion iter()? an stream protocol?
    // #[cfg(feature = "tcp")]
    // throughput_by(c, Transport::Tcp);
    #[cfg(feature = "tcp")]
    throughput_by(c, Transport::FramedTcp);
    #[cfg(feature = "websocket")]
    throughput_by(c, Transport::Ws);
}

criterion_group!(benches, latency /*throughput*/,);
criterion_main!(benches);
