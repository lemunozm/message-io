use super::endpoint::{Endpoint};
use super::remote_addr::{ToRemoteAddr};
use super::transport::{Transport};
use super::resource_id::{ResourceId};
use super::poll::{Poll, PollEvent};
use super::launcher::{DriverLauncher, ActionControllerList, EventProcessorList};
use super::driver::{NetEvent};

use strum::{IntoEnumIterator};

use crossbeam::channel::{self, Sender, Receiver, TryRecvError};

use crate::adapter::{SendStatus};
use crate::util::thread::{RunnableThread};

use std::sync::{
    Arc,
    atomic::{AtomicBool, Ordering},
};
use std::net::{SocketAddr, ToSocketAddrs};
use std::time::{Duration};
use std::io::{self};

pub fn split() -> (NetworkController, NetworkProcessor) {
    let mut launcher = DriverLauncher::default();
    Transport::iter().for_each(|transport| transport.mount_adapter(&mut launcher));

    let (poll, controllers, processors) = launcher.launch();

    let network_controller = NetworkController::new(controllers);
    let network_processor = NetworkProcessor::new(poll, processors);

    (network_controller, network_processor)
}

/// Shareable instance in charge of control all the connections.
pub struct NetworkController {
    controllers: ActionControllerList,
}

impl NetworkController {
    fn new(controllers: ActionControllerList) -> NetworkController {
        Self { controllers }
    }

    /// Creates a connection to the specific address.
    /// The endpoint, an identifier of the new connection, will be returned.
    /// If the connection can not be performed (e.g. the address is not reached)
    /// the corresponding IO error is returned.
    /// This function blocks until the resource has been connected and is ready to use.
    pub fn connect(
        &self,
        transport: Transport,
        addr: impl ToRemoteAddr,
    ) -> io::Result<(Endpoint, SocketAddr)> {
        let addr = addr.to_remote_addr().unwrap();
        log::trace!("Connect to {} by adapter: {}", addr, transport.id());
        self.controllers[transport.id() as usize].connect(addr).map(|(endpoint, addr)| {
            log::trace!("Connected to {}", endpoint);
            (endpoint, addr)
        })
    }

    /// Listen messages from specified transport.
    /// The giver address will be used as interface and listening port.
    /// If the port can be opened, a [ResourceId] identifying the listener is returned
    /// along with the local address, or an error if not.
    /// The address is returned despite you passed as parameter because
    /// when a `0` port is specified, the OS will give choose the value.
    pub fn listen(
        &self,
        transport: Transport,
        addr: impl ToSocketAddrs,
    ) -> io::Result<(ResourceId, SocketAddr)> {
        let addr = addr.to_socket_addrs().unwrap().next().unwrap();
        log::trace!("Listen by {} by adapter: {}", addr, transport.id());
        self.controllers[transport.id() as usize].listen(addr).map(|(resource_id, addr)| {
            log::trace!("Listening by {}", resource_id);
            (resource_id, addr)
        })
    }

    /// Remove a network resource.
    /// Returns `false` if the resource id doesn't exists.
    /// This is used to remove resources as connection or listeners.
    /// Resources of endpoints generated by listening in connection oriented transports
    /// can also be removed to close the connection.
    /// Removing an already connected connection implies a disconnection.
    /// Note that non-oriented connections as UDP use its listener resource to manage all
    /// remote endpoints internally, the remotes have not resource for themselfs.
    /// It means that all generated `Endpoint`s share the `ResourceId` of the listener and
    /// if you remove this resource you are removing the listener of all of them.
    /// For that cases there is no need to remove the resource because non-oriented connections
    /// have not connection itself to close, 'there is no spoon'.
    pub fn remove(&self, resource_id: ResourceId) -> bool {
        log::trace!("Remove {}", resource_id);
        let value = self.controllers[resource_id.adapter_id() as usize].remove(resource_id);
        log::trace!("Removed: {}", value);
        value
    }

    /// Send the data message thought the connection represented by the given endpoint.
    /// The funcion panics if the endpoint do not exists in the [`Network`].
    /// If the endpoint disconnects during the sending, a `Disconnected` event is generated.
    /// A [`SendStatus`] is returned with the information about the sending.
    pub fn send(&self, endpoint: Endpoint, data: &[u8]) -> SendStatus {
        log::trace!("Send {} bytes to {}", data.len(), endpoint);
        let status =
            self.controllers[endpoint.resource_id().adapter_id() as usize].send(endpoint, data);
        log::trace!("Send status: {:?}", status);
        status
    }
}

#[derive(Debug)]
enum StoredNetEvent {
    Connected(Endpoint, ResourceId),
    Message(Endpoint, Vec<u8>),
    Disconnected(Endpoint),
}

impl From<NetEvent<'_>> for StoredNetEvent {
    fn from(net_event: NetEvent<'_>) -> Self {
        match net_event {
            NetEvent::Connected(endpoint, id) => Self::Connected(endpoint, id),
            NetEvent::Message(endpoint, data) => Self::Message(endpoint, Vec::from(data)),
            NetEvent::Disconnected(endpoint) => Self::Disconnected(endpoint),
        }
    }
}

impl StoredNetEvent {
    fn borrow(&self) -> NetEvent<'_> {
        match self {
            Self::Connected(endpoint, id) => NetEvent::Connected(*endpoint, *id),
            Self::Message(endpoint, data) => NetEvent::Message(*endpoint, &data),
            Self::Disconnected(endpoint) => NetEvent::Disconnected(*endpoint),
        }
    }
}

struct NetworkState {
    poll: Poll,
    processors: EventProcessorList,
}

/// Instance in charge of process input network events.
/// These events are offered to the user as a [`NetEvent`] its processing data.
pub struct NetworkProcessor {
    thread: RunnableThread<NetworkState>,
    running: Arc<AtomicBool>,
    cached_event_receiver: Receiver<StoredNetEvent>,
    cached_event_sender: Sender<StoredNetEvent>,
}

impl NetworkProcessor {
    const SAMPLING_TIMEOUT: u64 = 50; //ms

    fn new(poll: Poll, processors: EventProcessorList) -> Self {
        let (cached_event_sender, cached_event_receiver) = channel::unbounded();

        let network_state = NetworkState { poll, processors };

        Self {
            thread: RunnableThread::new("message_io::NetworkThread", network_state),
            running: Arc::new(AtomicBool::new(false)),
            cached_event_sender,
            cached_event_receiver,
        }
    }

    /// Start to read events from the network.
    /// When the event is read, the `event_callback` is called from the internal network thread
    /// in order to offer a `NetEvent` referenced directly to the socket data, without copies.
    /// For that reason, if your computation is expensive, it is recomended to copy the
    /// message into a place that can be computed from other thread,
    /// since during that computation the internal thread will be blocked.
    ///
    /// It the processor is already running it would panic.
    pub fn run(&mut self, event_callback: impl Fn(NetEvent<'_>) -> bool + Send + 'static) {
        let timeout = Some(Duration::from_millis(Self::SAMPLING_TIMEOUT));

        // Mapping the event_callback to one that handle the stopped.
        let running = self.running.clone();
        let event_callback = move |event: NetEvent<'_>| {
            if !event_callback(event) {
                running.store(false, Ordering::Relaxed);
            }
        };

        // From the user perspective, the thread is running now (before the thread itself).
        self.running.store(true, Ordering::Relaxed);

        // Dispatch the catched events first.
        loop {
            if !self.running.load(Ordering::Relaxed) {
                return // The user stop running during the cached event processing
            }
            if !self.process_cached_event(&event_callback) {
                break // No more cached events
            }
        }

        let running = self.running.clone();
        let cached_event_sender = self.cached_event_sender.clone();
        self.thread
            .spawn(move |state| {
                Self::process_poll_event(
                    timeout,
                    &mut state.poll,
                    &mut state.processors,
                    &|net_event| {
                        if running.load(Ordering::Relaxed) {
                            event_callback(net_event);
                        }
                        else {
                            log::trace!("Cached {:?}", net_event);
                            cached_event_sender.send(net_event.into()).unwrap();
                        }
                    },
                );
            })
            .unwrap();
    }

    /// Stop the internal thread.
    /// After this call, the processor is considered not running, although the internal thread
    /// will continue to execute until the current internal network event processing was performed.
    /// If there are more pending events generated by the network that could be lost,
    /// they would be cached to read it later.
    /// See docs of [`NetworkThread::has_cached_events()`] for a deeper explanation.
    /// If you want to run the thread again, call [`NetworkProcessor::run()`].
    pub fn stop(&mut self) {
        self.running.store(false, Ordering::Relaxed);
        self.thread.finalize();
    }

    /// Wait until the processor stops.
    /// It will wait until a call to [`NetworkProcessor::stop()`] was performed and
    /// the thread ends its last processing.
    pub fn wait(&mut self) {
        self.thread.join()
    }

    /// Check if the internal thread is running.
    pub fn is_running(&self) -> bool {
        self.running.load(Ordering::Relaxed)
    }

    /// Check if there are cached events.
    ///
    /// There is no one-to-one relation among internal OS network events and the [`NetEvent`]
    /// offers to the user.
    /// This means that there are situations where an internal OS network event generates several
    /// [`NetEvent`] but the user only reads one:
    /// - The [`NetworkThread::run()`] is stopped but there was pending more `NetEvent` generated
    ///   by the same internal OS network event.
    /// - You call [`NetworkThread::receive()`] or [`NetworkThread::receive_timeout`] in order to
    ///   receive a `NetEvent` but there are more `NetEvent`s to process by the same internal
    ///   OS network event dispatched.
    /// In these situations, those remaining events would be lost. For that reason, they are cached
    /// and will be offered to the user the next time they call `run/receive`.
    ///
    /// Generally, this cached events are **totally transparently** to the user, but this function
    /// exposes their existance because this "caching" process could generate
    /// a slight performance impact in the mentioned situations that the user should expect.
    ///
    /// For example, in order to get the best performance is better to call
    /// [`NetworkThread::run()`] than [`NetworkThread::receive()`] in a loop, because the first one
    /// will not caching during it while this it running and the second one could perform
    /// this caching after each `receive()` call in the worst situation.
    pub fn has_cached_events(&self) -> bool {
        !self.cached_event_receiver.is_empty()
    }

    /// Receives only one `NetEvent` without running the internal thread.
    /// If `None` timeout is specified it would block until receive the [`NetEvent`].
    /// If timeout is specified it would block only during the specified [`Duration`].
    /// The funcion would return a boolean indication if the `event_callback` was called with
    /// a `NetEvent`.
    /// Note that this function could *cache events*, see docs about
    /// `NetworkThread::has_cached_events()` to a deeper explanation about it.
    /// If you want to receive [`NetEvent`], use [`NetworkThread::run()`] that
    /// offers better performance.
    pub fn receive(
        &mut self,
        timeout: Option<Duration>,
        event_callback: impl Fn(NetEvent<'_>) + Send + 'static
    ) -> bool {
        // Dispatch the catched events first.
        if self.process_cached_event(&event_callback) {
            return true // There was a cached event processed.
        }

        // No cached events, we dispatch an event poll to get a new one from the network.
        let was_processed = std::cell::Cell::new(false);
        let cached_event_sender = self.cached_event_sender.clone();
        let state = self.thread.state_mut().unwrap();
        Self::process_poll_event(timeout, &mut state.poll, &mut state.processors, &|net_event| {
            if !was_processed.get() {
                event_callback(net_event);
                was_processed.set(true);
            }
            else {
                log::trace!("Cached {:?}", net_event);
                cached_event_sender.send(net_event.into()).unwrap();
            }
        });
        was_processed.get()
    }

    fn process_cached_event(&self, event_callback: &dyn Fn(NetEvent<'_>)) -> bool {
        match self.cached_event_receiver.try_recv() {
            Ok(net_event) => {
                log::trace!("Read {:?} from cache", net_event);
                event_callback(net_event.borrow());
                true
            }
            Err(TryRecvError::Empty) => false,
            Err(TryRecvError::Disconnected) => unreachable!(),
        }
    }

    fn process_poll_event(
        timeout: Option<Duration>,
        poll: &mut Poll,
        processors: &mut EventProcessorList,
        event_callback: &dyn Fn(NetEvent<'_>),
    ) {
        poll.process_event(timeout, |poll_event| match poll_event {
            PollEvent::Network(resource_id) => {
                let adapter_id = resource_id.adapter_id() as usize;
                processors[adapter_id].process(resource_id, &|net_event| {
                    log::trace!("Processed {:?}", net_event);
                    event_callback(net_event);
                });
            }
            #[allow(dead_code)] //TODO: remove it with native event support
            PollEvent::Waker => todo!(),
        });
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::{Duration};

    lazy_static::lazy_static! {
        static ref TIMEOUT: Duration = Duration::from_millis(1000);
    }

    #[test]
    fn create_remove_listener() {
        let (controller, mut processor) = self::split();
        let (listener_id, _) = controller.listen(Transport::Tcp, "127.0.0.1:0").unwrap();
        assert!(controller.remove(listener_id)); // Do not generate an event
        assert!(!controller.remove(listener_id));
        assert!(!processor.receive(Some(*TIMEOUT), |_| unreachable!())); // No event
    }

    #[test]
    fn create_remove_listener_with_connection() {
        let (controller, mut processor) = self::split();
        let (listener_id, addr) = controller.listen(Transport::Tcp, "127.0.0.1:0").unwrap();
        controller.connect(Transport::Tcp, addr).unwrap();
        assert!(processor.receive(Some(*TIMEOUT), move |net_event| {
            match net_event {
                NetEvent::Connected(_, _) => {
                    assert!(controller.remove(listener_id));
                    assert!(!controller.remove(listener_id));
                }
                _ => unreachable!(),
            }
        }));
        assert!(!processor.receive(Some(*TIMEOUT), |_| unreachable!())); // No more events
    }

    #[test]
    fn processor_thread() {
        let mut processor = NetworkProcessor::new(Poll::default(), Vec::new());
        assert!(!processor.is_running());
        processor.run(|_| unreachable!());
        assert!(processor.is_running());
        processor.stop();
        assert!(!processor.is_running());
        processor.stop(); // Already stopped, nothing happens
        assert!(!processor.is_running());
        processor.run(|_| unreachable!());
        assert!(processor.is_running());
        // drops while running
    }

    #[test]
    #[should_panic]
    fn run_twice_without_stop() {
        let mut processor = NetworkProcessor::new(Poll::default(), Vec::new());
        processor.run(|_| unreachable!());
        processor.run(|_| unreachable!()); // panic: already running
    }
}
